{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbdCPT7D/zyNIb3+zXwGn7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshansrini26/object_lane_detection/blob/main/lane_object_detection_for_straight_curvy_roads.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY_Jdp5Sa22K",
        "outputId": "e7ec3ff5-d7ac-42e5-9bbc-3c0058c2617a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade opencv-python opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import copy"
      ],
      "metadata": {
        "id": "_BdeViUBbKUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gblur = cv2.GaussianBlur(gray,(5, 5),0)\n",
        "    thresh = cv2.threshold(gblur,150,255,cv2.THRESH_BINARY)[1]\n",
        "    return thresh"
      ],
      "metadata": {
        "id": "74hWR7VZcrYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regionOfInterest(img, polygon):\n",
        "    mask = np.zeros_like(img)\n",
        "    x1, y1 = polygon[0]\n",
        "    x2, y2 = polygon[1]\n",
        "    x3, y3 = polygon[2]\n",
        "    x4, y4 = polygon[3]\n",
        "    m1 = (y2-y1)/(x2-x1)\n",
        "    m2 = (y3-y2)/(x3-x2)\n",
        "    m3 = (y4-y3)/(x4-x3)\n",
        "    m4 = (y4-y1)/(x4-x1)\n",
        "    b1 = y1 - m1*x1\n",
        "    b2 = y2 - m2*x2\n",
        "    b3 = y3 - m3*x3\n",
        "    b4 = y4 - m4*x4\n",
        "\n",
        "    for i in range(mask.shape[0]):\n",
        "        for j in range(mask.shape[1]):\n",
        "            if i>=m1*j+b1 and i>=m2*j+b2 and i>=m3*j+b3 and i<=m4*j+b4:\n",
        "                mask[i][j] = 1\n",
        "\n",
        "    masked_img = np.multiply(mask, img)\n",
        "    return masked_img"
      ],
      "metadata": {
        "id": "O9L1Q2fAcz5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def slopeIntercept(line):\n",
        "    m = (line[1][1]-line[0][1])/(line[1][0]-line[0][0])\n",
        "    b = line[1][1] - m*line[1][0]\n",
        "    return m, b"
      ],
      "metadata": {
        "id": "4_o53JnedaDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removeCloseLines(linelist, m):\n",
        "    linelist_copy = copy.deepcopy(linelist)\n",
        "\n",
        "    for line in linelist:\n",
        "        m1, _ = slopeIntercept(line)\n",
        "        if abs(m-m1)<=0.5:\n",
        "            linelist_copy.remove(line)\n",
        "\n",
        "    return linelist_copy"
      ],
      "metadata": {
        "id": "rfxKAP7fddKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lineDetection(img, masked_img, solid_line_previous, dashed_line_previous):\n",
        "    img_copy = copy.deepcopy(img)\n",
        "    height, width = masked_img.shape\n",
        "    linesP = cv2.HoughLinesP(masked_img, 1, np.pi/180, 50, None, 30, 20)\n",
        "    linelist = linesP.tolist()\n",
        "    linelist = [tuple((line[0][:2], line[0][2:])) for line in linelist]\n",
        "    line_length = []\n",
        "    for line in linelist:\n",
        "        line_length.append(math.dist(line[0], line[1]))\n",
        "\n",
        "    try:\n",
        "        solid_line = linelist[line_length.index(max(line_length))]\n",
        "        linelist.remove(solid_line)\n",
        "    except ValueError:\n",
        "        solid_line = solid_line_previous\n",
        "\n",
        "    m, b = slopeIntercept(solid_line)\n",
        "    linelist = removeCloseLines(linelist, m)\n",
        "    initial = (int((height*0.6-b)/m), int(height*0.6))\n",
        "    final = (int((height-b)/m), height)\n",
        "    detected_line = cv2.line(img_copy, initial, final, (0,255,0), 5)\n",
        "\n",
        "    line_length = []\n",
        "\n",
        "    for line in linelist:\n",
        "        line_length.append(math.dist(line[0], line[1]))\n",
        "\n",
        "    try:\n",
        "        dashed_line = linelist[line_length.index(max(line_length))]\n",
        "    except ValueError:\n",
        "        dashed_line = dashed_line_previous\n",
        "\n",
        "    m, b = slopeIntercept(dashed_line)\n",
        "    initial = (int((height*0.6-b)/m), int(height*0.6))\n",
        "    final = (int((height-b)/m), height)\n",
        "    detected_line = cv2.line(detected_line, initial, final, (0,0,255), 5)\n",
        "\n",
        "    return detected_line, solid_line, dashed_line"
      ],
      "metadata": {
        "id": "IoAxFZZwdgv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video = cv2.VideoCapture(\"straight_lane.mp4\")"
      ],
      "metadata": {
        "id": "7w72rQ61dlEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video = cv2.VideoCapture(\"straight_lane.mp4\")\n",
        "out = cv2.VideoWriter('straight_lane_detection.avi', cv2.VideoWriter_fourcc(*'MJPG'), 25, (960,540))\n",
        "solid_line_previous = None\n",
        "dashed_line_previous = None\n",
        "print(\"Generating video output...\\n\")\n",
        "\n",
        "while True:\n",
        "    isTrue, img = video.read()\n",
        "    if isTrue == False:\n",
        "        break\n",
        "    processed_img = preprocessing(img)\n",
        "    height, width = processed_img.shape\n",
        "    polygon = [(int(width*0.1), height), (int(width*0.45), int(height*0.6)), (int(width*0.55), int(height*0.6)), (int(0.95*width), height)]\n",
        "    masked_img = regionOfInterest(processed_img, polygon)\n",
        "    detected_lines, solid_line, dashed_line = lineDetection(img, masked_img, solid_line_previous, dashed_line_previous)\n",
        "    solid_line_previous = solid_line\n",
        "    dashed_line_previous = dashed_line\n",
        "    out.write(detected_lines)\n",
        "\n",
        "# Release video objects\n",
        "out.release()\n",
        "video.release()\n",
        "cv2.destroyAllWindows()  # Close all OpenCV windows\n",
        "print(\"Video output generated.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWUWlOBOd4uH",
        "outputId": "f4500ada-4809-45c0-8d12-1b4551515a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating video output...\n",
            "\n",
            "Video output generated.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the MobileNet-SSD model files\n",
        "!wget -O deploy.prototxt https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/deploy.prototxt\n",
        "!wget -O mobilenet_iter_73000.caffemodel https://github.com/chuanqi305/MobileNet-SSD/raw/master/mobilenet_iter_73000.caffemodel"
      ],
      "metadata": {
        "id": "vcvKiH_yd7XW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2feb9b-43a4-4230-8903-0fa6b489aeb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-06 12:35:28--  https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/deploy.prototxt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44667 (44K) [text/plain]\n",
            "Saving to: ‘deploy.prototxt’\n",
            "\n",
            "\rdeploy.prototxt       0%[                    ]       0  --.-KB/s               \rdeploy.prototxt     100%[===================>]  43.62K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-10-06 12:35:28 (6.39 MB/s) - ‘deploy.prototxt’ saved [44667/44667]\n",
            "\n",
            "--2024-10-06 12:35:28--  https://github.com/chuanqi305/MobileNet-SSD/raw/master/mobilenet_iter_73000.caffemodel\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/mobilenet_iter_73000.caffemodel [following]\n",
            "--2024-10-06 12:35:28--  https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/mobilenet_iter_73000.caffemodel\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23306119 (22M) [application/octet-stream]\n",
            "Saving to: ‘mobilenet_iter_73000.caffemodel’\n",
            "\n",
            "mobilenet_iter_7300 100%[===================>]  22.23M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-10-06 12:35:29 (195 MB/s) - ‘mobilenet_iter_73000.caffemodel’ saved [23306119/23306119]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained MobileNet-SSD model\n",
        "net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'mobilenet_iter_73000.caffemodel')"
      ],
      "metadata": {
        "id": "fAttSfQNhwzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
        "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
        "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
        "           \"sofa\", \"train\", \"tvmonitor\"]"
      ],
      "metadata": {
        "id": "aMztwisyidKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gblur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    thresh = cv2.threshold(gblur, 150, 255, cv2.THRESH_BINARY)[1]\n",
        "    return thresh"
      ],
      "metadata": {
        "id": "nOZRN11QihuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regionOfInterest(img, polygon):\n",
        "    mask = np.zeros_like(img)\n",
        "    x1, y1 = polygon[0]\n",
        "    x2, y2 = polygon[1]\n",
        "    x3, y3 = polygon[2]\n",
        "    x4, y4 = polygon[3]\n",
        "    m1 = (y2 - y1) / (x2 - x1)\n",
        "    m2 = (y3 - y2) / (x3 - x2)\n",
        "    m3 = (y4 - y3) / (x4 - x3)\n",
        "    m4 = (y4 - y1) / (x4 - x1)\n",
        "    b1 = y1 - m1 * x1\n",
        "    b2 = y2 - m2 * x2\n",
        "    b3 = y3 - m3 * x3\n",
        "    b4 = y4 - m4 * x4\n",
        "\n",
        "    for i in range(mask.shape[0]):\n",
        "        for j in range(mask.shape[1]):\n",
        "            if i >= m1 * j + b1 and i >= m2 * j + b2 and i >= m3 * j + b3 and i <= m4 * j + b4:\n",
        "                mask[i][j] = 1\n",
        "\n",
        "    masked_img = np.multiply(mask, img)\n",
        "    return masked_img"
      ],
      "metadata": {
        "id": "dCHEl8ObiodG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find slope and y-intercept of a line\n",
        "def slopeIntercept(line):\n",
        "    m = (line[1][1] - line[0][1]) / (line[1][0] - line[0][0])\n",
        "    b = line[1][1] - m * line[1][0]\n",
        "    return m, b"
      ],
      "metadata": {
        "id": "rDCQgv9niry4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove multiple lines detected on the same lane side\n",
        "def removeCloseLines(linelist, m):\n",
        "    linelist_copy = copy.deepcopy(linelist)\n",
        "\n",
        "    for line in linelist:\n",
        "        m1, _ = slopeIntercept(line)\n",
        "        if abs(m - m1) <= 0.5:\n",
        "            linelist_copy.remove(line)\n",
        "\n",
        "    return linelist_copy"
      ],
      "metadata": {
        "id": "XpnRqO9eiuDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that draws lines on the image\n",
        "def lineDetection(img, masked_img, solid_line_previous, dashed_line_previous):\n",
        "    img_copy = copy.deepcopy(img)\n",
        "    height, width = masked_img.shape\n",
        "    linesP = cv2.HoughLinesP(masked_img, 1, np.pi / 180, 50, None, 30, 20)\n",
        "    linelist = linesP.tolist()\n",
        "    linelist = [tuple((line[0][:2], line[0][2:])) for line in linelist]\n",
        "    line_length = []\n",
        "    for line in linelist:\n",
        "        line_length.append(math.dist(line[0], line[1]))\n",
        "\n",
        "    try:\n",
        "        solid_line = linelist[line_length.index(max(line_length))]\n",
        "        linelist.remove(solid_line)\n",
        "    except ValueError:\n",
        "        solid_line = solid_line_previous\n",
        "\n",
        "    m, b = slopeIntercept(solid_line)\n",
        "    linelist = removeCloseLines(linelist, m)\n",
        "    initial = (int((height * 0.6 - b) / m), int(height * 0.6))\n",
        "    final = (int((height - b) / m), height)\n",
        "    detected_line = cv2.line(img_copy, initial, final, (0, 255, 0), 5)\n",
        "\n",
        "    line_length = []\n",
        "\n",
        "    for line in linelist:\n",
        "        line_length.append(math.dist(line[0], line[1]))\n",
        "\n",
        "    try:\n",
        "        dashed_line = linelist[line_length.index(max(line_length))]\n",
        "    except ValueError:\n",
        "        dashed_line = dashed_line_previous\n",
        "\n",
        "    m, b = slopeIntercept(dashed_line)\n",
        "    initial = (int((height * 0.6 - b) / m), int(height * 0.6))\n",
        "    final = (int((height - b) / m), height)\n",
        "    detected_line = cv2.line(detected_line, initial, final, (0, 0, 255), 5)\n",
        "\n",
        "    return detected_line, solid_line, dashed_line"
      ],
      "metadata": {
        "id": "Pk2Zy8qaiwOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Object detection function\n",
        "def objectDetection(img, net):\n",
        "    h, w = img.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 0.007843, (300, 300), 127.5)\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "\n",
        "    for i in range(detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence > 0.5:\n",
        "            idx = int(detections[0, 0, i, 1])\n",
        "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "            label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
        "            cv2.rectangle(img, (startX, startY), (endX, endY), (255, 0, 0), 2)\n",
        "            y = startY - 15 if startY - 15 > 15 else startY + 15\n",
        "            cv2.putText(img, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "    return img"
      ],
      "metadata": {
        "id": "apNdD3Loizoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main video processing loop\n",
        "video = cv2.VideoCapture(\"straight_lane.mp4\")\n",
        "out = cv2.VideoWriter('straight_lane_detection_output.mp4', cv2.VideoWriter_fourcc(*'XVID'), 25, (960, 540))\n",
        "solid_line_previous = None\n",
        "dashed_line_previous = None\n",
        "print(\"Generating video output...\\n\")\n",
        "\n",
        "while True:\n",
        "    isTrue, img = video.read()\n",
        "    if not isTrue:\n",
        "        break\n",
        "\n",
        "    processed_img = preprocessing(img)\n",
        "    height, width = processed_img.shape\n",
        "    polygon = [(int(width * 0.1), height), (int(width * 0.45), int(height * 0.6)),\n",
        "               (int(width * 0.55), int(height * 0.6)), (int(0.95 * width), height)]\n",
        "    masked_img = regionOfInterest(processed_img, polygon)\n",
        "\n",
        "    detected_lines, solid_line, dashed_line = lineDetection(img, masked_img, solid_line_previous, dashed_line_previous)\n",
        "    solid_line_previous = solid_line\n",
        "    dashed_line_previous = dashed_line\n",
        "\n",
        "    # Object detection on the current frame\n",
        "    detected_img = objectDetection(detected_lines, net)\n",
        "\n",
        "    # Write the frame with both lane and object detection\n",
        "    out.write(detected_img)\n",
        "\n",
        "out.release()\n",
        "video.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(\"Video output generated with lane and object detection.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-JlWyGgi23f",
        "outputId": "552cf8eb-d50b-4743-f6ee-a7c081aa48c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating video output...\n",
            "\n",
            "Video output generated with lane and object detection.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the yolov3.cfg file\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "\n",
        "# Download the yolov3.weights file (this file is large, around 240 MB)\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m5tYYyUtP2o",
        "outputId": "72a9c5b1-5a0c-47d0-e404-13aa93b370a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-06 19:11:42--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg’\n",
            "\n",
            "\ryolov3.cfg            0%[                    ]       0  --.-KB/s               \ryolov3.cfg          100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-06 19:11:42 (51.5 MB/s) - ‘yolov3.cfg’ saved [8342/8342]\n",
            "\n",
            "--2024-10-06 19:11:42--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 162.0.215.52\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  24.0MB/s    in 15s     \n",
            "\n",
            "2024-10-06 19:11:57 (15.9 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load YOLOv3 model with the downloaded config and weights\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "\n",
        "# Get the names of the output layers\n",
        "layer_names = net.getLayerNames()\n",
        "\n",
        "# Fix for the getUnconnectedOutLayers() method\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]\n",
        "\n",
        "print(\"YOLOv3 model loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoTzzuUQjGw6",
        "outputId": "f5d14c75-7691-4771-9be4-598188a41a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv3 model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load the pre-trained YOLOv3 model\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "\n",
        "# Get the names of all the layers in the network\n",
        "layer_names = net.getLayerNames()\n",
        "\n",
        "# Get the names of the output layers, handling both 1D and 2D outputs correctly\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]\n",
        "\n",
        "print(\"Output layers:\", output_layers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUOOTbzps5zJ",
        "outputId": "6e7aed34-eca6-4586-86a6-dbda2510bf0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output layers: ['yolo_82', 'yolo_94', 'yolo_106']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading"
      ],
      "metadata": {
        "id": "-a40FDWTA7fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")"
      ],
      "metadata": {
        "id": "ei-w9JlctuWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the names of the output layers\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]\n"
      ],
      "metadata": {
        "id": "nWFEYY2DuaE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2bbEdSTunUN",
        "outputId": "e891442a-9baf-495d-e660-9cdb5fbb5b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-06 19:12:35--  https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘coco.names’\n",
            "\n",
            "\rcoco.names            0%[                    ]       0  --.-KB/s               \rcoco.names          100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-06 19:12:35 (32.0 MB/s) - ‘coco.names’ saved [625/625]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the COCO dataset labels\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n"
      ],
      "metadata": {
        "id": "RE5HB7fhucR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to detect objects\n",
        "def detectObjects(frame):\n",
        "    height, width, channels = frame.shape\n",
        "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outputs = net.forward(output_layers)\n",
        "\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "\n",
        "    for output in outputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "    return boxes, confidences, class_ids, indexes"
      ],
      "metadata": {
        "id": "6UL62_s6uee5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to draw detected objects\n",
        "def drawDetectedObjects(frame, boxes, confidences, class_ids, indexes):\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indexes:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            confidence = confidences[i]\n",
        "            color = (0, 255, 0)  # Bounding box color\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "            cv2.putText(frame, label + \" \" + str(round(confidence, 2)), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "    return frame"
      ],
      "metadata": {
        "id": "VXGl0fSnuvSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lane detection functions (as previously defined)\n",
        "def preprocessing(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "    gblur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    white_mask = cv2.threshold(gblur, 200, 255, cv2.THRESH_BINARY)[1]\n",
        "    lower_yellow = np.array([0, 100, 100])\n",
        "    upper_yellow = np.array([210, 255, 255])\n",
        "    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    return mask"
      ],
      "metadata": {
        "id": "ERvgwUcCuxYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regionOfInterest(img, polygon):\n",
        "    mask = np.zeros_like(img)\n",
        "    x1, y1 = polygon[0]\n",
        "    x2, y2 = polygon[1]\n",
        "    x3, y3 = polygon[2]\n",
        "    x4, y4 = polygon[3]\n",
        "    m1 = (y2 - y1) / (x2 - x1)\n",
        "    m2 = (y3 - y2) / (x3 - x2)\n",
        "    m3 = (y4 - y3) / (x4 - x3)\n",
        "    m4 = (y4 - y1) / (x4 - x1)\n",
        "    b1 = y1 - m1 * x1\n",
        "    b2 = y2 - m2 * x2\n",
        "    b3 = y3 - m3 * x3\n",
        "    b4 = y4 - m4 * x4\n",
        "\n",
        "    for i in range(mask.shape[0]):\n",
        "        for j in range(mask.shape[1]):\n",
        "            if i >= m1 * j + b1 and i >= m2 * j + b2 and i >= m3 * j + b3 and i <= m4 * j + b4:\n",
        "                mask[i][j] = 1\n",
        "\n",
        "    masked_img = np.multiply(mask, img)\n",
        "    return masked_img"
      ],
      "metadata": {
        "id": "bG1A-ns5wgfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def warp(img, source_points, destination_points, destn_size):\n",
        "    matrix = cv2.getPerspectiveTransform(source_points, destination_points)\n",
        "    warped_img = cv2.warpPerspective(img, matrix, destn_size)\n",
        "    return warped_img\n"
      ],
      "metadata": {
        "id": "e9-LFeQTwjoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unwarp(img, source_points, destination_points, source_size):\n",
        "    matrix = cv2.getPerspectiveTransform(destination_points, source_points)\n",
        "    unwarped_img = cv2.warpPerspective(img, matrix, source_size)\n",
        "    return unwarped_img"
      ],
      "metadata": {
        "id": "_ec3G3njwm7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fitCurve(img):\n",
        "    histogram = np.sum(img[img.shape[0] // 2:, :], axis=0)\n",
        "    midpoint = int(histogram.shape[0] / 2)\n",
        "    leftx_base = np.argmax(histogram[:midpoint])\n",
        "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
        "    nwindows = 50\n",
        "    margin = 100\n",
        "    minpix = 50\n",
        "    window_height = int(img.shape[0] / nwindows)\n",
        "    y, x = img.nonzero()\n",
        "    leftx_current = leftx_base\n",
        "    rightx_current = rightx_base\n",
        "    left_lane_indices = []\n",
        "    right_lane_indices = []\n",
        "\n",
        "    for window in range(nwindows):\n",
        "        win_y_low = img.shape[0] - (window + 1) * window_height\n",
        "        win_y_high = img.shape[0] - window * window_height\n",
        "        win_xleft_low = leftx_current - margin\n",
        "        win_xleft_high = leftx_current + margin\n",
        "        win_xright_low = rightx_current - margin\n",
        "        win_xright_high = rightx_current + margin\n",
        "\n",
        "        good_left_indices = ((y >= win_y_low) & (y < win_y_high) & (x >= win_xleft_low) & (x < win_xleft_high)).nonzero()[0]\n",
        "        good_right_indices = ((y >= win_y_low) & (y < win_y_high) & (x >= win_xright_low) & (x < win_xright_high)).nonzero()[0]\n",
        "        left_lane_indices.append(good_left_indices)\n",
        "        right_lane_indices.append(good_right_indices)\n",
        "        if len(good_left_indices) > minpix:\n",
        "            leftx_current = int(np.mean(x[good_left_indices]))\n",
        "        if len(good_right_indices) > minpix:\n",
        "            rightx_current = int(np.mean(x[good_right_indices]))\n",
        "\n",
        "    left_lane_indices = np.concatenate(left_lane_indices)\n",
        "    right_lane_indices = np.concatenate(right_lane_indices)\n",
        "    leftx = x[left_lane_indices]\n",
        "    lefty = y[left_lane_indices]\n",
        "    rightx = x[right_lane_indices]\n",
        "    righty = y[right_lane_indices]\n",
        "    left_fit = np.polyfit(lefty, leftx, 2)\n",
        "    right_fit = np.polyfit(righty, rightx, 2)\n",
        "\n",
        "    return left_fit, right_fit"
      ],
      "metadata": {
        "id": "kupDcf0Xwo-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findPoints(img_shape, left_fit, right_fit):\n",
        "    ploty = np.linspace(0, img_shape[0] - 1, img_shape[0])\n",
        "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
        "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
        "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
        "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
        "\n",
        "    return pts_left, pts_right"
      ],
      "metadata": {
        "id": "2ONGNbrwwsUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fillCurves(img_shape, pts_left, pts_right):\n",
        "    pts = np.hstack((pts_left, pts_right))\n",
        "    img = np.zeros((img_shape[0], img_shape[1], 3), dtype='uint8')\n",
        "    cv2.fillPoly(img, np.int_([pts]), (0, 0, 255))\n",
        "    return img"
      ],
      "metadata": {
        "id": "N3HTE2aHwvVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def oneToThreeChannel(binary):\n",
        "    img = np.zeros((binary.shape[0], binary.shape[1], 3), dtype='uint8')\n",
        "    img[:, :, 0] = binary\n",
        "    img[:, :, 1] = binary\n",
        "    img[:, :, 2] = binary\n",
        "    return img"
      ],
      "metadata": {
        "id": "6f0-1YPMwx0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drawCurves(img, pts_left, pts_right):\n",
        "    img = oneToThreeChannel(img)\n",
        "    cv2.polylines(img, np.int32([pts_left]), isClosed=False, color=(0, 0, 255), thickness=10)\n",
        "    cv2.polylines(img, np.int32([pts_right]), isClosed=False, color=(0, 255, 255), thickness=10)\n",
        "    return img"
      ],
      "metadata": {
        "id": "1LB7T7P-wz1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concatenate(img1, img2, img3, img4, img5):\n",
        "    offset = 50\n",
        "    img3 = setOffset(img3, offset)\n",
        "    img4 = setOffset(img4, offset)\n",
        "    img5 = setOffset(img5, offset)\n",
        "    return np.concatenate((img1, img2, img3, img4, img5), axis=1)"
      ],
      "metadata": {
        "id": "6wXBiUv6w-nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setOffset(img, offset):\n",
        "    img = np.zeros((img.shape[0] + offset, img.shape[1], img.shape[2]), dtype='uint8')\n",
        "    img[offset:, :, :] = img\n",
        "    return img"
      ],
      "metadata": {
        "id": "bJ2B_BAoxAt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main processing loop\n",
        "video = cv2.VideoCapture(\"test_input.mp4\")\n",
        "height, width, _ = frame.shape\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "out = cv2.VideoWriter('test_output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "# Change the video writer to output in mp4 format\n",
        "print(\"Generating video output with lane and object detection...\\n\")\n",
        "\n",
        "while True:\n",
        "    isTrue, frame = video.read()\n",
        "    if not isTrue:\n",
        "        break\n",
        "\n",
        "    # Detect lanes\n",
        "    processed_img = preprocessing(frame)\n",
        "    height, width = processed_img.shape\n",
        "    polygon = [(int(width*0.15), int(height*0.94)),\n",
        "               (int(width*0.45), int(height*0.62)),\n",
        "               (int(width*0.58), int(height*0.62)),\n",
        "               (int(0.95*width), int(0.94*height))]\n",
        "\n",
        "    masked_img = regionOfInterest(processed_img, polygon)\n",
        "    source_points = np.float32([[int(width*0.49), int(height*0.62)],\n",
        "                                 [int(width*0.58), int(height*0.62)],\n",
        "                                 [int(width*0.15), int(height*0.94)],\n",
        "                                 [int(0.95*width), int(0.94*height)]])\n",
        "    destination_points = np.float32([[0,0], [400,0], [0, 960], [400, 960]])\n",
        "    warped_img_size = (400, 960)\n",
        "\n",
        "    warped_img = warp(masked_img, source_points, destination_points, warped_img_size)\n",
        "    kernel = np.ones((11,11), np.uint8)\n",
        "    opening = cv2.morphologyEx(warped_img, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    left_fit, right_fit = fitCurve(opening)\n",
        "    pts_left, pts_right = findPoints(warped_img.shape, left_fit, right_fit)\n",
        "    fill_curves = fillCurves(warped_img.shape, pts_left, pts_right)\n",
        "    unwarped_fill_curves = unwarp(fill_curves, source_points, destination_points, (width, height))\n",
        "    lane_overlay = cv2.addWeighted(frame, 1, unwarped_fill_curves, 1, 0)\n",
        "\n",
        "    # Detect objects\n",
        "    boxes, confidences, class_ids, indexes = detectObjects(frame)\n",
        "    frame_with_objects = drawDetectedObjects(frame, boxes, confidences, class_ids, indexes)\n",
        "\n",
        "    # Combine lane detection and object detection\n",
        "    result = cv2.addWeighted(lane_overlay, 0.6, frame_with_objects, 0.4, 0)\n",
        "\n",
        "    # Write the frame to output video\n",
        "    out.write(result)\n",
        "\n",
        "out.release()\n",
        "video.release()\n",
        "print(\"Video output with lane and object detection generated.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6k3ULeexMLi",
        "outputId": "d91a0d8e-12f5-4eaa-934e-0c874ac79bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating video output with lane and object detection...\n",
            "\n",
            "Video output with lane and object detection generated.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thXx5uWAxXgv",
        "outputId": "37f575a3-a65b-4f7a-cdf4-9fa17081fae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the output video\n",
        "files.download('test_output.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "HgfhSLWDzwB5",
        "outputId": "eaed7835-e9c9-49c5-b705-fcb33ea49c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_491aee30-0893-4c0f-abee-760bfc67dce6\", \"test_output.mp4\", 17241590)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Preprocessing function (convert to grayscale, apply Gaussian blur, Canny edge detection)\n",
        "def preprocessing(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "    return edges\n",
        "\n",
        "# Region of interest masking function\n",
        "def regionOfInterest(img, polygon):\n",
        "    mask = np.zeros_like(img)\n",
        "    cv2.fillPoly(mask, [polygon], 255)\n",
        "    masked_img = cv2.bitwise_and(img, mask)\n",
        "    return masked_img\n",
        "\n",
        "# Warp image to top-down view\n",
        "def warp(img, src_points, dst_points, size):\n",
        "    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
        "    warped = cv2.warpPerspective(img, matrix, size)\n",
        "    return warped\n",
        "\n",
        "# Unwarp image to normal view\n",
        "def unwarp(img, src_points, dst_points, size):\n",
        "    matrix = cv2.getPerspectiveTransform(dst_points, src_points)\n",
        "    unwarped = cv2.warpPerspective(img, matrix, size)\n",
        "    return unwarped\n",
        "\n",
        "# Fit curves using polynomial\n",
        "def fitCurveOptimized(img, left_fit, right_fit):\n",
        "    y, x = img.nonzero()\n",
        "    margin = 100\n",
        "    left_lane_indices = ((x > (left_fit[0] * y ** 2 + left_fit[1] * y + left_fit[2] - margin)) &\n",
        "                         (x < (left_fit[0] * y ** 2 + left_fit[1] * y + left_fit[2] + margin)))\n",
        "    right_lane_indices = ((x > (right_fit[0] * y ** 2 + right_fit[1] * y + right_fit[2] - margin)) &\n",
        "                          (x < (right_fit[0] * y ** 2 + right_fit[1] * y + right_fit[2] + margin)))\n",
        "\n",
        "    if len(left_lane_indices) == 0 or len(right_lane_indices) == 0:\n",
        "        return None, None\n",
        "\n",
        "    leftx = x[left_lane_indices]\n",
        "    lefty = y[left_lane_indices]\n",
        "    rightx = x[right_lane_indices]\n",
        "    righty = y[right_lane_indices]\n",
        "\n",
        "    if len(leftx) > 0 and len(rightx) > 0:\n",
        "        left_fit = np.polyfit(lefty, leftx, 2)\n",
        "        right_fit = np.polyfit(righty, rightx, 2)\n",
        "        return left_fit, right_fit\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "# Fill lane curves with red color\n",
        "def fillCurves(img_shape, pts_left, pts_right):\n",
        "    lane_area = np.zeros(img_shape, dtype=np.uint8)\n",
        "    pts = np.vstack([pts_left, np.flipud(pts_right)])\n",
        "    cv2.fillPoly(lane_area, np.int_([pts]), (0, 0, 255))  # Red color for lane marking\n",
        "    return lane_area\n",
        "\n",
        "# Object detection function using YOLO\n",
        "def detectObjects(frame):\n",
        "    height, width = frame.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "    layerOutputs = net.forward(layer_names)\n",
        "\n",
        "    boxes, confidences, class_ids = [], [], []\n",
        "\n",
        "    for output in layerOutputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                box = detection[0:4] * np.array([width, height, width, height])\n",
        "                centerX, centerY, w, h = box.astype(\"int\")\n",
        "                x = int(centerX - w / 2)\n",
        "                y = int(centerY - h / 2)\n",
        "                boxes.append([x, y, int(w), int(h)])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "    return boxes, confidences, class_ids, indexes\n",
        "\n",
        "# Draw detected objects\n",
        "def drawDetectedObjects(frame, boxes, confidences, class_ids, indexes):\n",
        "    if len(indexes) > 0:\n",
        "        for i in indexes.flatten():\n",
        "            x, y, w, h = boxes[i]\n",
        "            color = [int(c) for c in colors[class_ids[i]]]\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "            text = \"{}: {:.4f}\".format(labels[class_ids[i]], confidences[i])\n",
        "            cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "    return frame\n",
        "\n",
        "# Load YOLO model\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "layer_names = net.getLayerNames()\n",
        "layer_names = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "labels = open(\"coco.names\").read().strip().split(\"\\n\")\n",
        "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")\n",
        "\n",
        "# Video input and output\n",
        "video = cv2.VideoCapture(\"curved_lane.mp4\")\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "out = cv2.VideoWriter(\"curved_output.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "# Lane detection initial variables\n",
        "left_fit, right_fit = None, None\n",
        "source_points = np.float32([[200, height], [width-200, height], [width//2+50, height//2], [width//2-50, height//2]])\n",
        "destination_points = np.float32([[300, height], [width-300, height], [width-300, 0], [300, 0]])\n",
        "warped_img_size = (width, height)\n",
        "polygon = np.array([[200, height], [width-200, height], [width//2+50, height//2], [width//2-50, height//2]])\n",
        "\n",
        "# Main processing loop\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count % 2 != 0:  # Skip every other frame for efficiency\n",
        "        continue\n",
        "\n",
        "    # Resize frame for faster processing\n",
        "    small_frame = cv2.resize(frame, (width//2, height//2))\n",
        "\n",
        "    # Lane detection steps\n",
        "    processed_img = preprocessing(small_frame)\n",
        "    masked_img = regionOfInterest(processed_img, polygon)\n",
        "    warped_img = warp(masked_img, source_points, destination_points, warped_img_size)\n",
        "\n",
        "    # Check if the previous left_fit and right_fit are available\n",
        "    if left_fit is not None and right_fit is not None:\n",
        "        left_fit, right_fit = fitCurveOptimized(warped_img, left_fit, right_fit)\n",
        "\n",
        "    if left_fit is not None and right_fit is not None:\n",
        "        # Generating lane points\n",
        "        ploty = np.linspace(0, height - 1, height)\n",
        "        left_fitx = left_fit[0] * ploty**2 + left_fit[1] * ploty + left_fit[2]\n",
        "        right_fitx = right_fit[0] * ploty**2 + right_fit[1] * ploty + right_fit[2]\n",
        "\n",
        "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
        "        pts_right = np.array([np.transpose(np.vstack([right_fitx, ploty]))])\n",
        "\n",
        "        # Filling curves\n",
        "        fill_curves = fillCurves((height, width, 3), pts_left, pts_right)\n",
        "        unwarped_fill_curves = unwarp(fill_curves, source_points, destination_points, (width, height))\n",
        "\n",
        "        # Overlay the lane marking onto the frame\n",
        "        lane_overlay = cv2.addWeighted(frame, 1, unwarped_fill_curves, 0.3, 0)\n",
        "    else:\n",
        "        lane_overlay = frame  # Fallback to the original frame if no lane detected\n",
        "\n",
        "    # Perform object detection on the current frame\n",
        "    boxes, confidences, class_ids, indexes = detectObjects(lane_overlay)\n",
        "    lane_overlay = drawDetectedObjects(lane_overlay, boxes, confidences, class_ids, indexes)\n",
        "\n",
        "    # Save to output video\n",
        "    out.write(lane_overlay)\n",
        "\n",
        "# Release resources\n",
        "video.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "F46mmXIxz0l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3ITpTT5BQ4d",
        "outputId": "0d180645-2c9c-4699-ccd1-d941016bbf58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the output video\n",
        "files.download('curved_output.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "KQMuzcvmDAAK",
        "outputId": "97094dfd-0f04-4ebb-b204-4f653d042a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_731e2b68-a7a7-4bce-941e-ed08275db171\", \"curved_output.mp4\", 8881053)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BxUOLPWgDE8O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}